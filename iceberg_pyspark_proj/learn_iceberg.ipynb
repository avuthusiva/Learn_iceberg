{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ff014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/06/07 11:42:15 WARN Utils: Your hostname, codespaces-9815ba, resolves to a loopback address: 127.0.0.1; using 10.0.3.168 instead (on interface eth0)\n",
      "25/06/07 11:42:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/workspaces/Learn_iceberg/iceberg_pyspark_proj/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/codespace/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/codespace/.ivy2.5.2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-646e4111-ae8d-4c71-a34d-720fbec8e796;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.5_2.12/1.5.2/iceberg-spark-runtime-3.5_2.12-1.5.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2!iceberg-spark-runtime-3.5_2.12.jar (3812ms)\n",
      ":: resolution report :: resolve 1856ms :: artifacts dl 3819ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   1   |   1   |   0   ||   1   |   1   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-646e4111-ae8d-4c71-a34d-720fbec8e796\n",
      "\tconfs: [default]\n",
      "\t1 artifacts copied, 0 already retrieved (40629kB/46ms)\n",
      "25/06/07 11:42:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/07 11:42:24 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.\n",
      "java.lang.NoClassDefFoundError: scala/Serializable\n",
      "\tat org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions.apply(IcebergSparkSessionExtensions.scala:35)\n",
      "\tat org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions.apply(IcebergSparkSessionExtensions.scala:31)\n",
      "\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1059)\n",
      "\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)\n",
      "\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)\n",
      "\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)\n",
      "\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)\n",
      "\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.ClassNotFoundException: scala.Serializable\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
      "\t... 23 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .appName(\"IcebergLocalDevelopment\") \\\n",
    "  .config('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2') \\\n",
    "  .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "  .config(\"spark.sql.catalog.local.warehouse\", \"spark-warehouse/iceberg\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "# Verify Spark session creation\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f31f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table user_data\n",
    "          (\n",
    "          id int,\n",
    "          name varchar(30)\n",
    "          );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38259a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "insert into user_data values (1,'siva'),(2,'reddy'),(3,'meera');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cabc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1| siva|\n",
      "|  2|reddy|\n",
      "|  3|meera|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from user_data order by 1\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
